{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUqK6WyF7VSxRArguR/OLb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsingh9076/Building_LLM_Applications/blob/main/2.%20Data%20Preparation/data_loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "KKpJDFQnlqVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Necessary libraries\n",
        "\n",
        "!pip install pypdf\n",
        "!pip install langchain\n",
        "\n",
        "#for PDF file we need to import PyPDFLoader from langchain framework\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# for CSV file we need to import csv_loader\n",
        "# for Doc we need to import UnstructuredWordDocumentLoader\n",
        "# for Text document we need to import TextLoader\n",
        "#import os to set environment variable\n",
        "\n",
        "filePath = \"/content/A_miniature_version_of_the_course_can_be_found_here__1701743458.pdf\"\n",
        "loader = PyPDFLoader(filePath)\n",
        "#Load document\n",
        "pages = loader.load_and_split()\n",
        "print(pages[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbVuJBiQhDDZ",
        "outputId": "1dad8eb6-6555-437f-e105-e0531a6633ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.12)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.10)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.80)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "GeneratiYe AI Zith LargeLanguage Models.Course Notes : July, 2023\n",
            "Abhi-a5 Kim.3hiGenerative AI, and LLMs specifically, is a General Purpose Technology that is useful for a variety ofapplications. ɝLLMs can be, generally, thought of as a next word prediction modelɝ\n",
            "What is an LLM?LLMs are machine learning models that have learned from massive datasets of humanɫgeneratedcontent, finding statistical patterns to replicate humanɫlike abilities.Foundation models, also known as base models, have been trained on trillions of words for weeks ormonths using extensive compute power. These models have billions of parameters, which representtheir memory and enable sophisticated tasks.Interacting with LLMs differs from traditional programming paradigms. Instead of formalized codesyntax, you provide natural language prompts to the models.When you pass a prompt to the model, it predicts the next words and generates a completion. Thisprocess is known as inference.Part 1What is an LLMɛWhat are the Use Cases for application of LLMsɛWhat are Transformersɛ How was text generation done before Transformersɛ Transformer Architecture.How does a Transformer generate TextɛWhat is a PromptɛGenerative AI Project Life Cycle.How do you preɫtrain Large Language ModelsɛChallenges with preɫtraining LLMs.What is the optimal configuration for preɫtraining LLMsɛWhen is preɫtraining usefulɛPage 1Page 2Page 2Page 4Page 5Page 7Page 8Page 9Page 11Page 12PART 1LLM Pre-TrainingPART 2LLM Fine TuningPART 3RLHF & Application\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed-size chunking"
      ],
      "metadata": {
        "id": "HuKFb5Iilz7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"What is an LLM?LLMs are machine learning models that have learned from massive datasets of\n",
        "humanɫgeneratedcontent, finding statistical patterns to replicate humanɫlike abilities.\n",
        "\n",
        "Foundation models,\n",
        "also known as base models, have been trained on trillions of words for weeks ormonths using extensive\n",
        "compute power. These models have billions of parameters, which representtheir memory and enable\n",
        "sophisticated tasks.Interacting with LLMs differs from traditional programming paradigms.\n",
        "\n",
        "\n",
        "Instead of formalized codesyntax, you provide natural language prompts to the models.\n",
        "When you pass a prompt to the model, it predicts the next words and generates a completion.\n",
        "\n",
        "\n",
        "Thisprocess is known as inference.Part 1What is an LLMɛWhat are the Use Cases for application of\n",
        "LLMsɛWhat are Transformersɛ How was text generation done before Transformersɛ Transformer Architecture.\n",
        "How does a Transformer generate TextɛWhat is a PromptɛGenerative AI Project Life Cycle.\n",
        "\n",
        "\n",
        "How do you preɫtrain Large Language ModelsɛChallenges with preɫtraining LLMs.\n",
        "\"\"\"\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 400,\n",
        "    chunk_overlap  = 20\n",
        ")\n",
        "docs = text_splitter.create_documents([text])\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsMItjHxkZ3q",
        "outputId": "01896391-8da8-4747-99a5-cb6c8695fc0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='What is an LLM?LLMs are machine learning models that have learned from massive datasets of\\nhumanɫgeneratedcontent, finding statistical patterns to replicate humanɫlike abilities.'),\n",
              " Document(page_content='Foundation models,\\nalso known as base models, have been trained on trillions of words for weeks ormonths using extensive\\ncompute power. These models have billions of parameters, which representtheir memory and enable\\nsophisticated tasks.Interacting with LLMs differs from traditional programming paradigms.'),\n",
              " Document(page_content='Instead of formalized codesyntax, you provide natural language prompts to the models.\\nWhen you pass a prompt to the model, it predicts the next words and generates a completion.'),\n",
              " Document(page_content='Thisprocess is known as inference.Part 1What is an LLMɛWhat are the Use Cases for application of\\nLLMsɛWhat are Transformersɛ How was text generation done before Transformersɛ Transformer Architecture.\\nHow does a Transformer generate TextɛWhat is a PromptɛGenerative AI Project Life Cycle.\\n\\n\\nHow do you preɫtrain Large Language ModelsɛChallenges with preɫtraining LLMs.')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence Splitting\n",
        "\n",
        "### Naive Splitter"
      ],
      "metadata": {
        "id": "cl8g05camFen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = text.split(\".\")\n",
        "docs"
      ],
      "metadata": {
        "id": "AP_ENtqpsUpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67035da-fd2a-4795-f68a-bbd3f73d6bb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What is an LLM?LLMs are machine learning models that have learned from massive datasets of\\nhumanɫgeneratedcontent, finding statistical patterns to replicate humanɫlike abilities',\n",
              " '\\n\\nFoundation models,\\nalso known as base models, have been trained on trillions of words for weeks ormonths using extensive\\ncompute power',\n",
              " ' These models have billions of parameters, which representtheir memory and enable\\nsophisticated tasks',\n",
              " 'Interacting with LLMs differs from traditional programming paradigms',\n",
              " '\\n\\n\\nInstead of formalized codesyntax, you provide natural language prompts to the models',\n",
              " '\\nWhen you pass a prompt to the model, it predicts the next words and generates a completion',\n",
              " '\\n\\n\\nThisprocess is known as inference',\n",
              " 'Part 1What is an LLMɛWhat are the Use Cases for application of\\nLLMsɛWhat are Transformersɛ How was text generation done before Transformersɛ Transformer Architecture',\n",
              " '\\nHow does a Transformer generate TextɛWhat is a PromptɛGenerative AI Project Life Cycle',\n",
              " '\\n\\n\\nHow do you preɫtrain Large Language ModelsɛChallenges with preɫtraining LLMs',\n",
              " '\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9BRHBxuqlE9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}