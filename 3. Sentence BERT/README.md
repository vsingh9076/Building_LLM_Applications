## Embedding Methods

![image](https://github.com/vsingh9076/Building_LLM_Applications/assets/46970126/a81074c4-6220-4586-82e1-4974234e3133)

Embeddings are a type of word representation (with numerical vectors) that allows words with similar meanings to have a similar representation.

These vectors can be learned by a variety of machine-learning algorithms and large datasets of texts. One of the main roles of word embeddings is to provide input features for downstream tasks like text classification and information retrieval.

Several word embedding methods have been proposed in the past decade, here are some of them.
